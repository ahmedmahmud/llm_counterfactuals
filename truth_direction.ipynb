{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d8dc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils\n",
    "import pandas as pd\n",
    "from nnsight import LanguageModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "from geometry_of_truth.visualization_utils import collect_acts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583f7da",
   "metadata": {},
   "source": [
    "Load in model, 4-bit quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bb4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"meta-llama/Llama-3.1-8B\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "model = LanguageModel(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099df54c",
   "metadata": {},
   "source": [
    "We first test if our source prompt with few-shot true/false classification works, and the output token distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97459300",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"is pretty damned funny. This statement is postitive: TRUE\n",
    "though ford and neeson capably hold our interest , but its just not a thrilling movie. This statement is positive: FALSE\n",
    "far less sophisticated and. This statement is positive: FALSE\n",
    "acted and directed, it's clear that washington most certainly has a new career ahead of him. This statement is positive: TRUE\n",
    "this car is beautiful. This statement is positive:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca14b494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: '<|begin_of_text|>'\n",
      "  1: 'is'\n",
      "  2: ' pretty'\n",
      "  3: ' damned'\n",
      "  4: ' funny'\n",
      "  5: '.'\n",
      "  6: ' This'\n",
      "  7: ' statement'\n",
      "  8: ' is'\n",
      "  9: ' post'\n",
      " 10: 'itive'\n",
      " 11: ':'\n",
      " 12: ' TRUE'\n",
      " 13: '\\n'\n",
      " 14: 'though'\n",
      " 15: ' ford'\n",
      " 16: ' and'\n",
      " 17: ' ne'\n",
      " 18: 'eson'\n",
      " 19: ' cap'\n",
      " 20: 'ably'\n",
      " 21: ' hold'\n",
      " 22: ' our'\n",
      " 23: ' interest'\n",
      " 24: ','\n",
      " 25: ' but'\n",
      " 26: ' its'\n",
      " 27: ' just'\n",
      " 28: ' not'\n",
      " 29: ' a'\n",
      " 30: ' thrilling'\n",
      " 31: ' movie'\n",
      " 32: '.'\n",
      " 33: ' This'\n",
      " 34: ' statement'\n",
      " 35: ' is'\n",
      " 36: ' positive'\n",
      " 37: ':'\n",
      " 38: ' FALSE'\n",
      " 39: '\\n'\n",
      " 40: 'far'\n",
      " 41: ' less'\n",
      " 42: ' sophisticated'\n",
      " 43: ' and'\n",
      " 44: '.'\n",
      " 45: ' This'\n",
      " 46: ' statement'\n",
      " 47: ' is'\n",
      " 48: ' positive'\n",
      " 49: ':'\n",
      " 50: ' FALSE'\n",
      " 51: '\\n'\n",
      " 52: 'acted'\n",
      " 53: ' and'\n",
      " 54: ' directed'\n",
      " 55: ','\n",
      " 56: ' it'\n",
      " 57: \"'s\"\n",
      " 58: ' clear'\n",
      " 59: ' that'\n",
      " 60: ' washington'\n",
      " 61: ' most'\n",
      " 62: ' certainly'\n",
      " 63: ' has'\n",
      " 64: ' a'\n",
      " 65: ' new'\n",
      " 66: ' career'\n",
      " 67: ' ahead'\n",
      " 68: ' of'\n",
      " 69: ' him'\n",
      " 70: '.'\n",
      " 71: ' This'\n",
      " 72: ' statement'\n",
      " 73: ' is'\n",
      " 74: ' positive'\n",
      " 75: ':'\n",
      " 76: ' TRUE'\n",
      " 77: '\\n'\n",
      " 78: 'this'\n",
      " 79: ' car'\n",
      " 80: ' is'\n",
      " 81: ' beautiful'\n",
      " 82: '.'\n",
      " 83: ' This'\n",
      " 84: ' statement'\n",
      " 85: ' is'\n",
      " 86: ' positive'\n",
      " 87: ':'\n"
     ]
    }
   ],
   "source": [
    "utils.print_token_ids(prompt_text, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b718ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab4813d1f9a4ea9a22b1288a8b8118e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 predictions:\n",
      "  8378 ĠTRUE (' TRUE'): 0.7578\n",
      "  7989 ĠFALSE (' FALSE'): 0.2178\n",
      "  62495 ĠUNKNOWN (' UNKNOWN'): 0.0029\n",
      "  837 Ġtrue (' true'): 0.0027\n",
      "  6781 ĠUN (' UN'): 0.0013\n",
      "  8014 ĠNE (' NE'): 0.0012\n",
      "  3082 ĠTrue (' True'): 0.0012\n",
      "  5091 ĠTR (' TR'): 0.0011\n",
      "  21260 TRUE ('TRUE'): 0.0011\n",
      "  4276 ĠNOT (' NOT'): 0.0007\n"
     ]
    }
   ],
   "source": [
    "with model.trace(prompt_text):\n",
    "    logits = model.lm_head.output[0, -1].save()\n",
    "\n",
    "utils.print_topk_tokens(logits, tokenizer, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82e135e",
   "metadata": {},
   "source": [
    "We then perform the process of finding the \"truth direction\" and perturbing the activations of the statement to try and flip the classifier.\n",
    "\n",
    "[1] https://github.com/saprmarks/geometry-of-truth/blob/main/interventions.py#L13\n",
    "\n",
    "[2] https://github.com/saprmarks/geometry-of-truth/blob/main/probes.py#L58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828f4be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_layer = 7\n",
    "end_layer = 13\n",
    "\n",
    "train_datasets = ['cities', 'neg_cities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9361b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts, labels = [], []\n",
    "\n",
    "for dataset in train_datasets:\n",
    "    acts.append(collect_acts(dataset, 'llama-3.1-8b', end_layer, noperiod=True).to('cuda:0'))\n",
    "    labels.append(torch.Tensor(pd.read_csv(f'geometry_of_truth/datasets/{dataset}.csv')['label'].tolist()).to('cuda:0'))\n",
    "\n",
    "acts, labels = torch.cat(acts), torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50d59399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From MMProbe\n",
    "true_acts, false_acts = acts[labels==1], acts[labels==0]\n",
    "true_mean, false_mean = true_acts.mean(0), false_acts.mean(0)\n",
    "direction = (true_mean - false_mean).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ccceeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_suffix: 6\n",
      "len suffix is +1 because of <bos> token\n",
      "top-10 predictions:\n",
      "  8378 ĠTRUE (' TRUE'): 0.5156\n",
      "  7989 ĠFALSE (' FALSE'): 0.4551\n",
      "  62495 ĠUNKNOWN (' UNKNOWN'): 0.0045\n",
      "  8014 ĠNE (' NE'): 0.0022\n",
      "  837 Ġtrue (' true'): 0.0021\n",
      "  6781 ĠUN (' UN'): 0.0020\n",
      "  4276 ĠNOT (' NOT'): 0.0011\n",
      "  905 Ġfalse (' false'): 0.0009\n",
      "  3082 ĠTrue (' True'): 0.0009\n",
      "  21260 TRUE ('TRUE'): 0.0009\n"
     ]
    }
   ],
   "source": [
    "len_suffix = len(model.tokenizer.encode(\"This statement is positive:\"))\n",
    "print(f\"len_suffix: {len_suffix}\")\n",
    "print(\"len suffix is +1 because of <bos> token\")\n",
    "\n",
    "with model.trace(prompt_text):\n",
    "    for layer in range(start_layer, end_layer + 1):\n",
    "        model.model.layers[layer].output[0][:, -len_suffix - 1, :] -= direction\n",
    "    activations = [layer.output[0].save() for layer in model.model.layers]\n",
    "    logits = model.lm_head.output[0, -1].save()\n",
    "\n",
    "utils.print_topk_tokens(logits, tokenizer, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a7beafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 88, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(activations[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10953826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 4096])\n"
     ]
    }
   ],
   "source": [
    "source_layer = 20\n",
    "\n",
    "# 78:83 range for the statement\n",
    "source_activations = activations[source_layer][:, 78:83, :]\n",
    "\n",
    "print(source_activations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba104447",
   "metadata": {},
   "source": [
    "Test if our few-shot target prompt works to do sentence identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665e974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prompt_text_test = \"\"\"i love pizza->i love pizza;\n",
    "the weather is nice->the weather is nice;\n",
    "they didn't enjoy the show->they didn't enjoy the show;\n",
    "i hate the rain\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363eec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love pizza->i love pizza;\n",
      "the weather is nice->the weather is nice;\n",
      "they didn't enjoy the show->they didn't enjoy the show;\n",
      "i hate the rain->i hate the rain;\n",
      "i'm tired of this->i'm tired\n"
     ]
    }
   ],
   "source": [
    "with model.generate(target_prompt_text_test, max_new_tokens=15):\n",
    "    output_tokens = model.generator.output.save()\n",
    "\n",
    "print(tokenizer.decode(output_tokens[0].cpu(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1e16a",
   "metadata": {},
   "source": [
    "Add placeholder tokens to perform patchscopes on and check generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b3ffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_prompt_text_test = \"\"\"i love pizza->i love pizza;\n",
    "the weather is nice->the weather is nice;\n",
    "they didn't enjoy the show->they didn't enjoy the show;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a4cd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt_len = 5\n",
    "\n",
    "target_prompt_tokens = torch.cat([\n",
    "  tokenizer(target_prompt_text_test, return_tensors=\"pt\").input_ids[0].to(device), \n",
    "  torch.tensor([tokenizer.convert_tokens_to_ids(\"?\")] * stmt_len).to(device)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fd34114",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c830ad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love pizza->i love pizza;\n",
      "the weather is nice->the weather is nice;\n",
      "they didn't enjoy the show->they didn't enjoy the show;\n",
      "?????->this car is beautiful;\n",
      "he is a good man.->he is a good man;\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "with model.generate(target_prompt_tokens, max_new_tokens=20):\n",
    "    model.model.layers[target_layer].output[0][:, -stmt_len :, :] = source_activations\n",
    "    output_tokens = model.generator.output.save()\n",
    "\n",
    "generated = model.tokenizer.decode(output_tokens[0].cpu(), skip_special_tokens=True)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879708c5",
   "metadata": {},
   "source": [
    "We get back out the same statement we started with: this car is beautiful"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
